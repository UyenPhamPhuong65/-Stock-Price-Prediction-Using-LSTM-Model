# -*- coding: utf-8 -*-
"""Stock Price Prediction Using LSTM Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1B2j27cG0zSiJkhXQR243TQqFlU5ay3Sj
"""

!pip install --upgrade mplfinance

#import basic libraries
import numpy as np
import pandas as pd

#import for processing
import random
import math
import datetime as dt
import matplotlib.dates as mdates

#import for visualization
import matplotlib.pyplot as plt
from mplfinance.original_flavor import candlestick_ohlc

#import libraries for model training
from keras.models import Sequential
from keras.layers import LSTM, Dense, Dropout
from keras.callbacks import ModelCheckpoint, EarlyStopping
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error

#reading the dataset
df = pd.read_csv("/content/stock_price_5yrs.csv")
df.head()

#dropping unnecessary columns
df.drop(['Adj Close'], axis=1, inplace=True)
df.drop(['Volume'], axis=1, inplace=True)

#DATA UNDERSTANDING

#get all the stock name
stock_tick_names = df['Name'].unique()
print(stock_tick_names)

#extracting data for a specific stock name
stock_name = input("Enter a stock price name: ")
specific_df = df['Name'] == stock_name
specific_df = df[specific_df]
specific_df.head()

#line chart of closing prices over time
specific_df.plot('Date', 'Close', color="red")
plt.title(f'Closing Prices Over Time of {stock_name}')
plt.ylabel('Close Price')
plt.xticks(rotation=45)
plt.grid(True)
plt.show()

#monthly seasonality of closing prices
specific_df['Date'] = pd.to_datetime(specific_df['Date'])
specific_df['Month'] = specific_df['Date'].dt.month

monthly_average = specific_df.groupby('Month')['Close'].mean()

plt.figure(figsize=(15, 6))
plt.plot(monthly_average.index, monthly_average.values, marker='o')
plt.title(f'Monthly Seasonality of {stock_name}')
plt.xlabel('Months')
plt.ylabel('Average Closing Price')
plt.xticks(range(1, 13), ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])
plt.grid(True)
plt.show()

specific_df.head()

new_df = specific_df.reset_index()['Close']

#normalizing the data using MinMaxScaler
scaler = MinMaxScaler()
scaled_data=scaler.fit_transform(np.array(new_df).reshape(-1,1))

#splitting data into training and testing sets
train_size = int(len(scaled_data) * 0.8)  #80% for training
train_data, test_data = scaled_data[:train_size], scaled_data[train_size:]

#defining the sequence length
n_past = 60

#preparing sequences for LSTM
X_train, y_train = [], []
for i in range(n_past, len(train_data)):
    X_train.append(train_data[i - n_past:i, 0])
    y_train.append(train_data[i, 0])
X_train, y_train = np.array(X_train), np.array(y_train)

#preparing sequences for the test set
X_test, y_test = [], []
for i in range(n_past, len(test_data)):
    X_test.append(test_data[i - n_past:i, 0])
    y_test.append(test_data[i, 0])
X_test, y_test = np.array(X_test), np.array(y_test)

print("Training set size:-")
print(X_train.shape), print(y_train.shape)
print("\n")
print("Testing set size:-")
print(X_test.shape), print(y_test.shape)

#reshaping input data for LSTM([samples, time steps, features])
X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)
X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)

#BUILDING LSTM MODEL

#initializing a sequential model
model = Sequential()

#first LSTM layer with 50 units, input shape, and return sequences
model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))
model.add(Dropout(0.2))         # Adding dropout to prevent overfitting

#second LSTM layer with 50 units and return sequences
model.add(LSTM(units=50, return_sequences=True))
model.add(Dropout(0.2))

#third LSTM layer with 50 units
model.add(LSTM(units=50))
model.add(Dropout(0.2))

#add a dense output layer with one unit
model.add(Dense(units=1))

model.summary()

#COMPILING MODEL

model.compile(loss='mean_squared_error',optimizer='adam')

checkpoints = ModelCheckpoint(filepath = 'my_weights.h5', save_best_only = True)
early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)

#training LSTM model
model.fit(X_train, y_train,
          validation_data=(X_test,y_test),
          epochs=100,
          batch_size=32,
          verbose=1,
          callbacks= [checkpoints, early_stopping])

#predicting and checking performance metrics
train_predict=model.predict(X_train)
test_predict=model.predict(X_test)

#transforming back to original form
train_predict=scaler.inverse_transform(train_predict)
test_predict=scaler.inverse_transform(test_predict)

#calculating train data RMSE
print(math.sqrt(mean_squared_error(y_train,train_predict)))
#calculating test data RMSE
print(math.sqrt(mean_squared_error(y_test,test_predict)))

#setting the number of previous time steps to consider for plotting
look_back = 60

#initializing an array for plotting the train predictions
trainPredictPlot = np.empty_like(new_df)
trainPredictPlot[:] = np.nan
#assigning the predicted values to the appropriate location for train predictions
trainPredictPlot[look_back:len(train_predict)+look_back] = train_predict.flatten()

#initializing an array for plotting the test predictions
testPredictPlot = np.empty_like(new_df)
testPredictPlot[:] = np.nan
#calculating the starting index for the test predictions
test_start = len(new_df) - len(test_predict)
#assigning the predicted values to the appropriate location for test predictions
testPredictPlot[test_start:] = test_predict.flatten()

#rescale the scaled data back to its original scale using the scaler
original_scaled_data = scaler.inverse_transform(scaled_data)

#plotting the baseline data, training predictions, and test predictions
plt.figure(figsize=(15, 6))
plt.plot(original_scaled_data, color='black', label=f"Actual {stock_name} price")
plt.plot(trainPredictPlot, color='red', label=f"Predicted {stock_name} price(train set)")
plt.plot(testPredictPlot, color='blue', label=f"Predicted {stock_name} price(test set)")

plt.title(f"{stock_name} share price")
plt.xlabel("time")
plt.ylabel(f"{stock_name} share price")
plt.legend()
plt.show()

#predicting data for the next 10 days
last_sequence = X_test[-1]

#reshape the last_sequence to match the input shape of the model
last_sequence = last_sequence.reshape(1, n_past, 1)

#predictions for the next 10 days
predictions_next_10_days = []
for _ in range(10):
    next_day_prediction = model.predict(last_sequence)
    predictions_next_10_days.append(next_day_prediction[0, 0])  # Get the predicted value
    last_sequence = np.roll(last_sequence, -1, axis=1)  # Shift the sequence by one day
    last_sequence[0, -1, 0] = next_day_prediction  # Update the last element with the new prediction

#transforming the predictions back to the original scale
predictions_next_10_days = scaler.inverse_transform(np.array(predictions_next_10_days).reshape(-1, 1))

#printing the predictions for the next 10 days
print("Predictions for the next 10 days:")
for i, prediction in enumerate(predictions_next_10_days, start=1):
    print(f"Day {i}: Predicted Price = {prediction[0]}")

plt.plot(predictions_next_10_days, marker='*')
plt.title(f'Predicted stock price of {stock_name} for next 10 days')
plt.xlabel('Days')
plt.ylabel('Price')
plt.xticks(range(0, 10), ['Day1', 'Day2', 'Day3', 'Day4', 'Day5', 'Day6', 'Day7', 'Day8', 'Day9', 'Day10'])
plt.grid(True)
plt.show()